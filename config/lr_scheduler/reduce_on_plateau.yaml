# @package _global_
lr_scheduler:
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    mode: ${monitor_mode}
    factor: 0.5
    patience: 5
    min_lr: 1e-9
  monitor: ${monitor_metric}
  interval: epoch
